{
 "metadata": {
  "name": "",
  "signature": "sha256:c44dffa0cc3601bbcdface37777688789472318b9648932f59acd5bb01195c0c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Multiple Linear Regression Lab"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this lab we will regress the price of an apartment on to several explanatory variables. The following instances comprise our training set:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "| price \t| size \t| num_bedrooms \t| age \t| city          \t|\n",
      "|-------\t|------\t|--------------\t|-----\t|---------------\t|\n",
      "| 2500  \t| 500  \t| 1            \t| 1   \t| New York      \t|\n",
      "| 2400  \t| 600  \t| 1            \t| 40  \t| San Francisco \t|\n",
      "| 900   \t| 800  \t| 2            \t| 2   \t| Chapel Hill   \t|\n",
      "| 1700  \t| 400  \t| 0            \t| 10  \t| New York      \t|\n",
      "| 2100  \t| 450  \t| 0            \t| 25  \t| New York      \t|\n",
      "| 3000  \t| 900  \t| 2            \t| 5   \t| San Francisco \t|\n",
      "| 700   \t| 700  \t| 1            \t| 6   \t| Chapel Hill   \t|"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Representing the Data and One-Hot Encoding"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# First, let's create a representation of the values of the response variable. We can simply create a list.\n",
      "y_train = [2500, 2400, 900, 1700, 2100, 3000, 700]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Creating `y` was easy. Now let's represent the explanatory variables.\n",
      "\n",
      "The `city` explanatory variable is categorical. How can we create a feature to represent it?  \n",
      "\n",
      "`city` has three possible values in this data set: `New York`, `San Francisco`, and `Chapel Hill`. We could represent each of these states with an integer. That is, we will represent `New York` with 0, `San Francisco` with 1, and `Chapel Hill` with 2. While this approach seems intuitive, it encodes an artificial order to the values of the variable. Cities have no natural order. We don't want to represent `Chapel Hill` as being twice `San Francisco`.\n",
      "\n",
      "Instead, we will create features using a technique called **one-hot**, or **one-of-k**, encoding. One-hot encoding creates a binary-valued feature for each of the possible values of the variable. That is, instead of representing the `city` explanatory variable with one integer-valued feature, we will represent it with three binary-valued features.\n",
      "\n",
      "`New York` = [1, 0, 0]\n",
      "`San Francisco` = [0, 1, 0]\n",
      "`Chapel Hill` = [0, 0, 1]\n",
      "\n",
      "One-hot encoding does not encode an artificial order, but does increase the number of features. Later we will discuss why using many features, or high-dimensional feature spaces, can be problematic, and how to mitigate those problems."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# One-hot encode the `city` explanatory variable, and create a list of lists to represent the features.\n",
      "# The first two training instances have been added for you.\n",
      "X_raw = [\n",
      "    [500, 1, 1, 1, 0, 0],\n",
      "    [600, 1, 40, 0, 1, 0],\n",
      "    [800, 2, 2, 0, 0, 1],\n",
      "    [400, 0, 10, 1, 0, 0],\n",
      "    [450, 0, 25, 1, 0, 0],\n",
      "    [900, 2, 5, 0, 1, 0],\n",
      "    [700, 1, 6, 0, 0, 1]\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Manually one-hot encoding will become tedious. sklearn can automatically one-hot encode dicts of explanatory variables.\n",
      "# Import the DictVectorizer class from the feature_extraction module.\n",
      "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html\n",
      "from sklearn.feature_extraction import DictVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Assume that your data is provided as a list of dicts.\n",
      "X_raw = [\n",
      "         {'size': 500, 'num_bedrooms': 1, 'age': 1, 'city': 'New York'},\n",
      "         {'size': 600, 'num_bedrooms': 1, 'age': 40, 'city': 'San Francisco'},\n",
      "         {'size': 800, 'num_bedrooms': 2, 'age': 2, 'city': 'Chapel Hill'},\n",
      "         {'size': 400, 'num_bedrooms': 0, 'age': 10, 'city': 'New York'},\n",
      "         {'size': 450, 'num_bedrooms': 0, 'age': 25, 'city': 'New York'},\n",
      "         {'size': 900, 'num_bedrooms': 2, 'age': 5, 'city': 'San Francisco'},\n",
      "         {'size': 700, 'num_bedrooms': 1, 'age': 6, 'city': 'Chapel Hill'}\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate a DictVectorizer\n",
      "vectorizer = DictVectorizer() # don't set sparse to False in order to get a sparse matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# DictVectorizer is a Transformer. Transformers implement the methods fit() and transform(). \n",
      "# First fit the vectorizer on your explanatory variables so that it can determine the features.\n",
      "vectorizer.fit(X_raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "DictVectorizer(dtype=<type 'numpy.float64'>, separator='=', sparse=True)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Then transform X using the vectorizer to one-hot encode the explanatory variables.\n",
      "X_train = vectorizer.transform(X_raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print the features\n",
      "print X_train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 4)\t1.0\n",
        "  (0, 2)\t1.0\n",
        "  (0, 0)\t1.0\n",
        "  (0, 5)\t500.0\n",
        "  (1, 4)\t1.0\n",
        "  (1, 3)\t1.0\n",
        "  (1, 0)\t40.0\n",
        "  (1, 5)\t600.0\n",
        "  (2, 4)\t2.0\n",
        "  (2, 1)\t1.0\n",
        "  (2, 0)\t2.0\n",
        "  (2, 5)\t800.0\n",
        "  (3, 4)\t0.0\n",
        "  (3, 2)\t1.0\n",
        "  (3, 0)\t10.0\n",
        "  (3, 5)\t400.0\n",
        "  (4, 4)\t0.0\n",
        "  (4, 2)\t1.0\n",
        "  (4, 0)\t25.0\n",
        "  (4, 5)\t450.0\n",
        "  (5, 4)\t2.0\n",
        "  (5, 3)\t1.0\n",
        "  (5, 0)\t5.0\n",
        "  (5, 5)\t900.0\n",
        "  (6, 4)\t1.0\n",
        "  (6, 1)\t1.0\n",
        "  (6, 0)\t6.0\n",
        "  (6, 5)\t700.0\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Those look weird. Check X_train's type\n",
      "type(X_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "scipy.sparse.csr.csr_matrix"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# X_train is a sparse matrix. We will discuss these more later. To get the dense form of a sparse matrix, use the method todense()\n",
      "# Note that DictVectorizer orders the features arbitrarily.\n",
      "X_train.todense()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "matrix([[   1.,    0.,    1.,    0.,    1.,  500.],\n",
        "        [  40.,    0.,    0.,    1.,    1.,  600.],\n",
        "        [   2.,    1.,    0.,    0.,    2.,  800.],\n",
        "        [  10.,    0.,    1.,    0.,    0.,  400.],\n",
        "        [  25.,    0.,    1.,    0.,    0.,  450.],\n",
        "        [   5.,    0.,    0.,    1.,    2.,  900.],\n",
        "        [   6.,    1.,    0.,    0.,    1.,  700.]])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Training the Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have created representations of the values of the response and explanatory variables for the training instances, let's train a regressor."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import LinearRegression from the linear_model module\n",
      "from sklearn.linear_model import LinearRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Instantiate a LinearRegression regressor\n",
      "regressor = LinearRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train (fit) the model\n",
      "regressor.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Inspecting the Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print the model's parameters. They are attributes of the object. Consult the documentation for their names.\n",
      "print regressor.intercept_\n",
      "print regressor.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1900.0\n",
        "[  6.46133244e+00  -2.88004687e+03  -7.29779043e+02  -1.09958152e+03\n",
        "   3.53431537e+02   1.63207231e+00]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Making Predictions"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Assume that you have the following test set.\n",
      "\n",
      "| price \t| size \t| num_bedrooms \t| age \t| city          \t|\n",
      "|-------\t|------\t|--------------\t|-----\t|---------------\t|\n",
      "| 2500  \t| 500  \t| 0            \t| 50  \t| New York      \t|\n",
      "| 2200  \t| 550  \t| 0            \t| 2   \t| San Francisco \t|\n",
      "| 1200  \t| 1000 \t| 2            \t| 12  \t| Chapel Hill   \t|\n",
      "| 3300  \t| 850  \t| 2            \t| 10  \t| New York      \t|"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a list of the values of the response variable for the test set\n",
      "y_test = [2500, 2200, 1200, 3300]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a list of dicts representing the explanatory variables.\n",
      "X_test_raw = [\n",
      "         {'size': 500, 'num_bedrooms': 0, 'age': 50, 'city': 'New York'},\n",
      "         {'size': 550, 'num_bedrooms': 0, 'age': 2, 'city': 'San Francisco'},\n",
      "         {'size': 1000, 'num_bedrooms': 2, 'age': 12, 'city': 'Chapel Hill'},\n",
      "         {'size': 850, 'num_bedrooms': 2, 'age': 10, 'city': 'New York'},\n",
      "]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now we need to create a feature representation for the test set's explanatory variables.\n",
      "# If we instantiate a new DictVectorizer and transform the test set, it might order the features differently than in the training data.\n",
      "# This would render the model meaningless.\n",
      "# vectorizer has been fit on the training data; all subsequent transformations it makes will have the same order.\n",
      "# TODO transform X_test_raw using vectorizer\n",
      "X_test = vectorizer.transform(X_test_raw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now print X_test\n",
      "print X_test\n",
      "X_test.todense()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  (0, 4)\t0.0\n",
        "  (0, 2)\t1.0\n",
        "  (0, 0)\t50.0\n",
        "  (0, 5)\t500.0\n",
        "  (1, 4)\t0.0\n",
        "  (1, 3)\t1.0\n",
        "  (1, 0)\t2.0\n",
        "  (1, 5)\t550.0\n",
        "  (2, 4)\t2.0\n",
        "  (2, 1)\t1.0\n",
        "  (2, 0)\t12.0\n",
        "  (2, 5)\t1000.0\n",
        "  (3, 4)\t2.0\n",
        "  (3, 2)\t1.0\n",
        "  (3, 0)\t10.0\n",
        "  (3, 5)\t850.0\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "matrix([[   50.,     0.,     1.,     0.,     0.,   500.],\n",
        "        [    2.,     0.,     0.,     1.,     0.,   550.],\n",
        "        [   12.,     1.,     0.,     0.,     2.,  1000.],\n",
        "        [   10.,     0.,     1.,     0.,     2.,   850.]])"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO print the parameters of the model. Manually predict the price of the first test instance.\n",
      "print regressor.intercept_\n",
      "print regressor.coef_\n",
      "\n",
      "# convert first test instance to numpy array\n",
      "import numpy as np\n",
      "test_instance_1 = np.squeeze(np.asarray(X_test.todense()[0]))\n",
      "\n",
      "sum(regressor.coef_ * test_instance_1) + regressor.intercept_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1900.0\n",
        "[  6.46133244e+00  -2.88004687e+03  -7.29779043e+02  -1.09958152e+03\n",
        "   3.53431537e+02   1.63207231e+00]\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "2309.3237361907336"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's make some predictions using the trained regressor.\n",
      "# TODO predict the value of the response variable for the test instances\n",
      "predictions = regressor.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print each of the predictions on a new line\n",
      "for p in predictions:\n",
      "    print p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2309.32373619\n",
        "1710.98091731\n",
        "1436.42450619\n",
        "3328.95882156\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Print each of the predictions and the corresponding true price on a new line\n",
      "# Hint: try the built-in function `enumerate`\n",
      "for i,p in enumerate(predictions):\n",
      "    print p, y_test[i]\n",
      "    \n",
      "# alternate way using zip\n",
      "# for p, t in zip(predictions, y_test):\n",
      "#    print p, t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2309.32373619 2500\n",
        "1710.98091731 2200\n",
        "1436.42450619 1200\n",
        "3328.95882156 3300\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Evaluating the Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now let's measure the model's performance.\n",
      "# use the estimator's score method to calculate r-squared.\n",
      "score = regressor.score(X_test, y_test)\n",
      "print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.852994574649\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO interpret the r-squared score. What does it mean? How well does the model perform?\n",
      "print '%.2f%% of the variance is explained by the model' % (score * 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "85.30% of the variance is explained by the model\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Improving the Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO Are all of the explanatory variables useful? \n",
      "# Does the model perform better using a subset of the explanatory variables? Try to improve the model's performance by using a subset of the explanatory variables.\n",
      "\n",
      "# make a copy of the raw training dataset and remove 'age' variable\n",
      "X_raw2 = [ xi.copy() for xi in X_raw ]\n",
      "[ xi.pop('age',None) for xi in X_raw2 ]\n",
      "print X_raw2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{'num_bedrooms': 1, 'city': 'New York', 'size': 500}, {'num_bedrooms': 1, 'city': 'San Francisco', 'size': 600}, {'num_bedrooms': 2, 'city': 'Chapel Hill', 'size': 800}, {'num_bedrooms': 0, 'city': 'New York', 'size': 400}, {'num_bedrooms': 0, 'city': 'New York', 'size': 450}, {'num_bedrooms': 2, 'city': 'San Francisco', 'size': 900}, {'num_bedrooms': 1, 'city': 'Chapel Hill', 'size': 700}]\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fit and transform explanatory variables for the training set\n",
      "vect2 = DictVectorizer()\n",
      "vect2.fit(X_raw2)\n",
      "X_train2 = vect2.transform(X_raw2)\n",
      "X_train2.todense()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "matrix([[   0.,    1.,    0.,    1.,  500.],\n",
        "        [   0.,    0.,    1.,    1.,  600.],\n",
        "        [   1.,    0.,    0.,    2.,  800.],\n",
        "        [   0.,    1.,    0.,    0.,  400.],\n",
        "        [   0.,    1.,    0.,    0.,  450.],\n",
        "        [   0.,    0.,    1.,    2.,  900.],\n",
        "        [   1.,    0.,    0.,    1.,  700.]])"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train the model using the training set and print the model's parameters\n",
      "regress2 = LinearRegression()\n",
      "regress2.fit(X_train2, y_train)\n",
      "print regress2.intercept_\n",
      "print regress2.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1900.0\n",
        "[ -2.42000000e+03  -4.17142857e+02  -5.20000000e+02   3.08571429e+02\n",
        "   1.14285714e+00]\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# make a copy of the raw test dataset and remove 'age' variable\n",
      "X_test_raw2 = [xi.copy() for xi in X_test_raw ]\n",
      "[ xi.pop('age',None) for xi in X_test_raw2 ]\n",
      "\n",
      "# then transform the explanatory variables using the same vectorizer fit to the training set\n",
      "X_test2 = vect2.transform(X_test_raw2)\n",
      "X_test2.todense()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "matrix([[    0.,     1.,     0.,     0.,   500.],\n",
        "        [    0.,     0.,     1.,     0.,   550.],\n",
        "        [    1.,     0.,     0.,     2.,  1000.],\n",
        "        [    0.,     1.,     0.,     2.,   850.]])"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# predict the prices for our test set, and print next to actual price\n",
      "predict2 = regress2.predict(X_test2)\n",
      "for p, t in zip(predict2, y_test):\n",
      "    print p, t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2054.28571429 2500\n",
        "2008.57142857 2200\n",
        "1240.0 1200\n",
        "3071.42857143 3300\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute the model's score for our test set and draw conclusion\n",
      "score2 = regress2.score(X_test2, y_test)\n",
      "print '%.2f%% of the variance is explained by the model' % (score2 * 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "87.21% of the variance is explained by the model\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Comparing to Simple Linear Regression Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO How does this model compare to a simple linear regression model? Train another model using only one of the explanatory variables."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# only keep size from raw traning dataset (remember, X_train3 has to be a list of lists)\n",
      "X_train3 = [ [xi.get('size',0)] for xi in X_raw ]\n",
      "print X_train3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[500], [600], [800], [400], [450], [900], [700]]\n",
        "7 7\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# train the model using the training set and print the model's parameters\n",
      "regress3 = LinearRegression()\n",
      "regress3.fit(X_train3, y_train)\n",
      "print regress3.intercept_\n",
      "print regress3.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2018.77133106\n",
        "[-0.19112628]\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# only keep size from raw test dataset (remember, X_test3 has to be a list of lists)\n",
      "X_test3 = [ [xi.get('size',0)] for xi in X_test_raw ]\n",
      "print X_test3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[500], [550], [1000], [850]]\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# predict the prices for our test set, and print next to actual price\n",
      "predict3 = regress3.predict(X_test3)\n",
      "for p, t in zip(predict3, y_test):\n",
      "    print p, t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1923.20819113 2500\n",
        "1913.65187713 2200\n",
        "1827.64505119 1200\n",
        "1856.31399317 3300\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute the model's score for our test set and draw conclusion\n",
      "score3 = regress3.score(X_test3, y_test)\n",
      "print '%.2f%% of the variance is explained by the model' % (score3 * 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-28.00% of the variance is explained by the model\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}